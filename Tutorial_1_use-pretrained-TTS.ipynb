{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ea3ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Easy Inferencing with üê∏ TTS ‚ö°\n",
    "\n",
    "#### You want to quicly synthesize speech using Coqui üê∏ TTS model?\n",
    "\n",
    "üí°: Grab a pre-trained model and use it to synthesize speech using any speaker voice, including yours! ‚ö°\n",
    "\n",
    "üê∏ TTS comes with a list of pretrained models and speaker voices. You can even start a local demo server that you can open it on your favorite web browser and üó£Ô∏è .\n",
    "\n",
    "In this notebook, we will: \n",
    "```\n",
    "1. List available pre-trained üê∏ TTS models\n",
    "2. Run a üê∏ TTS model\n",
    "3. Listen to the synthesized wave üì£\n",
    "4. Run multispeaker üê∏ TTS model \n",
    "```\n",
    "So, let's jump right in!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5c2a5-46eb-42fd-b550-2a052546857e",
   "metadata": {},
   "source": [
    "## Install üê∏ TTS ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2aec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: You must give at least one requirement to install (see \"pip help install\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\tomsl\\.conda\\envs\\cv1_1\\lib\\site-packages (23.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install --use-pep517\n",
    "! pip install -U pip\n",
    "! pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -e .[all,dev,notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07a273",
   "metadata": {},
   "source": [
    "## ‚úÖ List available pre-trained üê∏ TTS models\n",
    "\n",
    "Coqui üê∏TTS comes with a list of pretrained models for different model types (ex: TTS, vocoder), languages, datasets used for training and architectures. \n",
    "\n",
    "You can either use your own model or the release models under üê∏TTS.\n",
    "\n",
    "Use `tts --list_models` to find out the availble models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608d203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'tts' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! tts --list_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dd7ab",
   "metadata": {},
   "source": [
    "## ‚úÖ Run a üê∏ TTS model\n",
    "\n",
    "#### **First things first**: Using a release model and default vocoder:\n",
    "\n",
    "You can simply copy the full model name from the list above and use it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9e4608-16ec-4dcd-bd6b-bd10d62286f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'tts' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!tts --text \"hello world\" \\\n",
    "--model_name \"tts_models/en/ljspeech/glow-tts\" \\\n",
    "--out_path output.wav\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2cb14-1aba-400e-a219-8ce44d9410be",
   "metadata": {},
   "source": [
    "## üì£ Listen to the synthesized wave üì£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe63ef4-9284-4461-9dda-1ca7483a8f9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tomsl\\Documents\\Huureenhuis\\Voice Clone\\TTS\\notebooks\\Tutorial_1_use-pretrained-TTS.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomsl/Documents/Huureenhuis/Voice%20Clone/TTS/notebooks/Tutorial_1_use-pretrained-TTS.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mIPython\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tomsl/Documents/Huureenhuis/Voice%20Clone/TTS/notebooks/Tutorial_1_use-pretrained-TTS.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m IPython\u001b[39m.\u001b[39;49mdisplay\u001b[39m.\u001b[39;49mAudio(\u001b[39m\"\u001b[39;49m\u001b[39moutput.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\lib\\display.py:129\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m rate \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m Audio\u001b[39m.\u001b[39m_make_wav(data, rate, normalize)\n",
      "\u001b[1;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67d178-1ebe-49c7-9a47-0593251bdb96",
   "metadata": {},
   "source": [
    "### **Second things second**:\n",
    "\n",
    "üî∂ A TTS model can be either trained on a single speaker voice or multispeaker voices. This training choice is directly reflected on the inference ability and the available speaker voices that can be used to synthesize speech. \n",
    "\n",
    "üî∂ If you want to run a multispeaker model from the released models list, you can first check the speaker ids using `--list_speaker_idx` flag and use this speaker voice to synthesize speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b18839-f750-4a61-bbb0-c964acaecab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the possible speaker IDs.\n",
    "!tts --model_name \"tts_models/en/vctk/vits\" \\\n",
    "--list_speaker_idxs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4365a9d-f922-4b14-88b0-d2b22a245b2e",
   "metadata": {},
   "source": [
    "## üí¨ Synthesize speech using speaker ID üí¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be0403-d13e-4d9b-99c2-c10b85154063",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tts --text \"Trying out specific speaker voice\"\\\n",
    "--out_path spkr-out.wav --model_name \"tts_models/en/vctk/vits\" \\\n",
    "--speaker_idx \"p341\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a560a-f9c8-48ce-aaa6-afdf516c01f6",
   "metadata": {},
   "source": [
    "## üì£ Listen to the synthesized speaker specific wave üì£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed485b0a-dfd5-4a7e-a571-ebf74bdfc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"spkr-out.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84636a38-097e-4dad-933b-0aeaee650e92",
   "metadata": {},
   "source": [
    "üî∂ If you want to use an external speaker to synthesize speech, you need to supply `--speaker_wav` flag along with an external speaker encoder path and config file, as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb15fa-123a-4282-a127-87b50dc70365",
   "metadata": {},
   "source": [
    "First we need to get the speaker encoder model, its config and a referece `speaker_wav`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f1b13-560c-4fed-bafd-e38ec9712359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/config_se.json\n",
    "!wget https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/model_se.pth.tar\n",
    "!wget https://github.com/coqui-ai/TTS/raw/speaker_encoder_model/tests/data/ljspeech/wavs/LJ001-0001.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac1912-5054-4a68-8357-6d20fd99cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tts --model_name tts_models/multilingual/multi-dataset/your_tts \\\n",
    "--encoder_path model_se.pth.tar \\\n",
    "--encoder_config config_se.json \\\n",
    "--speaker_wav LJ001-0001.wav \\\n",
    "--text \"Are we not allowed to dim the lights so people can see that a bit better?\"\\\n",
    "--out_path spkr-out.wav \\\n",
    "--language_idx \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ddce58-8aca-4f69-84c3-645ae1b12e7d",
   "metadata": {},
   "source": [
    "## üì£ Listen to the synthesized speaker specific wave üì£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc889adc-9c71-4232-8e85-bfc8f76476f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"spkr-out.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29101d01-0b01-4153-a216-5dae415a5dd6",
   "metadata": {},
   "source": [
    "## üéâ Congratulations! üéâ You now know how to use a TTS model to synthesize speech! \n",
    "Follow up with the next tutorials to learn more adnavced material."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
